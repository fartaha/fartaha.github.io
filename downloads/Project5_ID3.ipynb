{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hTeD-qgjZv8"
      },
      "source": [
        "**ID3 Decision Tree Algorithm Implementation with Post Pruning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7qPp64VjaKc"
      },
      "outputs": [],
      "source": [
        "# ---------------------------------\n",
        "# Machine Learning Project work\n",
        "# Taha Heidari\n",
        "# 2021\n",
        "# ID3 Decision Tree Algorithm Implementation and Analysis with Post Pruning\n",
        "# Dataset: Adult-Income Dataset\n",
        "# ---------------------------------\n",
        "# Obejctives: \n",
        "# Task 1-a : ID3 Decision Tree Algorithm Implementation without using ready-made Python Libraries\n",
        "# Task 1-b : ID3 Decision Tree and Post Pruning without using ready-made Python Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6mmpX4E7EXU"
      },
      "source": [
        "**Import librarys**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ud7lQ_KV_Zm6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pprint import pprint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBKSY-qLsRvV"
      },
      "source": [
        "**Import Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DK22pFNwswZe"
      },
      "outputs": [],
      "source": [
        "# For Google Colab\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/MyDrive/Codes for Projects/Machin Learning/HW1/Adult/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J1lksGv6_dpk"
      },
      "outputs": [],
      "source": [
        "# Import\n",
        "data_train=pd.read_csv('adult.train.10k.discrete', \n",
        "                       names=['50k', 'Workclass', 'Education', 'Marital-Status', 'Occupation', 'Relationship', 'Race', 'Sex', 'Native-Country'])\n",
        "data_test=pd.read_csv('adult.test.10k.discrete', \n",
        "                      names=['50k', 'Workclass', 'Education', 'Marital-Status', 'Occupation', 'Relationship', 'Race', 'Sex', 'Native-Country'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dvvX8xPGVxZC"
      },
      "outputs": [],
      "source": [
        "# Change class column position\n",
        "data_train = data_train.rename(columns={'50k': 'class'})\n",
        "data_test = data_test.rename(columns={'50k': 'class'})\n",
        "cols = ['Workclass', 'Education', 'Marital-Status', 'Occupation', 'Relationship', 'Race', 'Sex', 'Native-Country', 'class']\n",
        "data_train = data_train[cols]\n",
        "data_test = data_test[cols]\n",
        "# data_train['class'] = pd.factorize(data_train['class'])[0]\n",
        "# data_test['class'] = pd.factorize(data_test['class'])[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X1cYlgddPBJq"
      },
      "outputs": [],
      "source": [
        "data_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sdFrU9zfN-_a"
      },
      "outputs": [],
      "source": [
        "data_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQDGDiAfhvkh"
      },
      "source": [
        "**Tree Functions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0727SnO9PhN-"
      },
      "outputs": [],
      "source": [
        "# Entropy\n",
        "def entropy(target_col):\n",
        "    elements,counts = np.unique(target_col,return_counts = True)\n",
        "    entropy = np.sum([(-counts[i]/np.sum(counts))*np.log2(counts[i]/np.sum(counts)) for i in range(len(elements))])\n",
        "    return entropy\n",
        "\n",
        "# Information Gain\n",
        "def InfoGain(data,split_attribute_name,target_name=\"class\"):\n",
        "    total_entropy = entropy(data[target_name])    \n",
        "    vals,counts= np.unique(data[split_attribute_name],return_counts=True)\n",
        "    Weighted_Entropy = np.sum([(counts[i]/np.sum(counts))*entropy(data.where(data[split_attribute_name]==vals[i]).dropna()[target_name]) for i in range(len(vals))])    \n",
        "    Information_Gain = total_entropy - Weighted_Entropy\n",
        "    return Information_Gain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lzvrgNtLPsbO"
      },
      "outputs": [],
      "source": [
        "def ID3(data,originaldata,features,target_attribute_name=\"class\",parent_node_class = None):\n",
        "    if len(np.unique(data[target_attribute_name])) <= 1:\n",
        "        return np.unique(data[target_attribute_name])[0]    \n",
        "    elif len(data)==0:\n",
        "        return np.unique(originaldata[target_attribute_name])[np.argmax(np.unique(originaldata[target_attribute_name],return_counts=True)[1])]\n",
        "    elif len(features) ==0:\n",
        "        return parent_node_class\n",
        "    else:\n",
        "        parent_node_class = np.unique(data[target_attribute_name])[np.argmax(np.unique(data[target_attribute_name],return_counts=True)[1])]\n",
        "        item_values = [InfoGain(data,feature,target_attribute_name) for feature in features]\n",
        "        best_feature_index = np.argmax(item_values)\n",
        "        best_feature = features[best_feature_index]\n",
        "        tree = {best_feature:{}}    \n",
        "        features = [i for i in features if i != best_feature]        \n",
        "        for value in np.unique(data[best_feature]):\n",
        "            value = value\n",
        "            sub_data = data.where(data[best_feature] == value).dropna()\n",
        "            subtree = ID3(sub_data,originaldata,features,target_attribute_name,parent_node_class)\n",
        "            tree[best_feature][value] = subtree\n",
        "        return tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pnkNhaRVPnLG"
      },
      "outputs": [],
      "source": [
        "def predict(query,tree,default = 1):\n",
        "    for key in list(query.keys()):\n",
        "        if key in list(tree.keys()):\n",
        "            try:\n",
        "                result = tree[key][query[key]] \n",
        "            except:\n",
        "                return default\n",
        "            result = tree[key][query[key]]\n",
        "            if isinstance(result,dict):\n",
        "                return predict(query,result)\n",
        "            else:\n",
        "                return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sA5_FxBjP2tL"
      },
      "outputs": [],
      "source": [
        "def train_test_split(dataset, train_size):\n",
        "    dataset_shuffled = dataset.sample(frac=1).reset_index(drop=True)\n",
        "    training_data = dataset_shuffled.iloc[:int(data_train.shape[0]*(train_size))].reset_index(drop=True)\n",
        "    testing_data = dataset_shuffled.iloc[int(data_train.shape[0]*(train_size)):].reset_index(drop=True)\n",
        "    return training_data, testing_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1zaLArhP5Wx"
      },
      "outputs": [],
      "source": [
        "def test(data,tree):\n",
        "    queries = data.iloc[:,:-1].to_dict(orient = \"records\")\n",
        "    predicted = pd.DataFrame(columns=[\"predicted\"]) \n",
        "    for i in range(len(data)):\n",
        "        predicted.loc[i,\"predicted\"] = predict(queries[i],tree,1.0) \n",
        "    return (np.sum(predicted[\"predicted\"] == data[\"class\"])/len(data))*100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUibe2O7-aWi"
      },
      "source": [
        "# **1-a**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SVp-AkMji1-",
        "outputId": "b34202e9-5090-4838-dc39-a6ef12a6be17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---------------------\n",
            "Tree # 1\n",
            "Tree Accuracy: 76.32 %\n",
            "---------------------\n",
            "Tree # 2\n",
            "Tree Accuracy: 75.85 %\n",
            "---------------------\n",
            "Tree # 3\n",
            "Tree Accuracy: 74.68 %\n",
            "---------------------\n",
            "Tree # 4\n",
            "Tree Accuracy: 75.08 %\n",
            "---------------------\n",
            "Tree # 5\n",
            "Tree Accuracy: 75.36 %\n",
            "---------------------\n",
            "Avrage Tree Accuracy: 75.46 %\n",
            "---------------------\n"
          ]
        }
      ],
      "source": [
        "acc_list = []\n",
        "print('---------------------')\n",
        "for count in range(5):\n",
        "  training_data, _ = train_test_split(data_train, train_size=0.25)\n",
        "  _, testing_data = train_test_split(data_test, train_size=0.0)\n",
        "  tree = ID3(training_data,training_data,training_data.columns[:-1])\n",
        "  acc = test(testing_data, tree)\n",
        "  acc_list.append(acc)\n",
        "  print('Tree #', str(count+ 1))\n",
        "  print('Tree Accuracy:', str(round(acc, 2)),'%')\n",
        "  print('---------------------')\n",
        "print('Avrage Tree Accuracy:', str(round(sum(acc_list) / len(acc_list), 2)), '%')\n",
        "print('---------------------')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7ocltDyy9dU"
      },
      "source": [
        "# **1-b**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUM2zAp9y9dc",
        "outputId": "49551a36-9f67-4e92-afae-570d9a0161ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---------------------\n",
            "Training Size: 25 %\n",
            "---------------------\n",
            "Tree # 1 Accuracy: 75.29 %\n",
            "Tree # 2 Accuracy: 76.24 %\n",
            "Tree # 3 Accuracy: 75.27 %\n",
            "Tree # 4 Accuracy: 75.57 %\n",
            "Tree # 5 Accuracy: 76.09 %\n",
            "---------------------\n",
            "Avrage Tree Accuracy for Training Size 25 % : 75.69 %\n",
            "---------------------\n",
            "Training Size: 35 %\n",
            "---------------------\n",
            "Tree # 1 Accuracy: 76.06 %\n",
            "Tree # 2 Accuracy: 76.58 %\n",
            "Tree # 3 Accuracy: 76.26 %\n",
            "Tree # 4 Accuracy: 75.99 %\n",
            "Tree # 5 Accuracy: 76.22 %\n",
            "---------------------\n",
            "Avrage Tree Accuracy for Training Size 35 % : 76.22 %\n",
            "---------------------\n",
            "Training Size: 45 %\n",
            "---------------------\n",
            "Tree # 1 Accuracy: 77.27 %\n",
            "Tree # 2 Accuracy: 76.86 %\n",
            "Tree # 3 Accuracy: 76.85 %\n",
            "Tree # 4 Accuracy: 77.09 %\n",
            "Tree # 5 Accuracy: 76.61 %\n",
            "---------------------\n",
            "Avrage Tree Accuracy for Training Size 45 % : 76.94 %\n",
            "---------------------\n",
            "Training Size: 55 %\n",
            "---------------------\n",
            "Tree # 1 Accuracy: 76.71 %\n",
            "Tree # 2 Accuracy: 76.87 %\n",
            "Tree # 3 Accuracy: 76.66 %\n",
            "Tree # 4 Accuracy: 76.41 %\n",
            "Tree # 5 Accuracy: 77.24 %\n",
            "---------------------\n",
            "Avrage Tree Accuracy for Training Size 55 % : 76.78 %\n",
            "---------------------\n",
            "Training Size: 65 %\n",
            "---------------------\n",
            "Tree # 1 Accuracy: 76.88 %\n",
            "Tree # 2 Accuracy: 77.49 %\n",
            "Tree # 3 Accuracy: 77.13 %\n",
            "Tree # 4 Accuracy: 76.76 %\n",
            "Tree # 5 Accuracy: 77.37 %\n",
            "---------------------\n",
            "Avrage Tree Accuracy for Training Size 65 % : 77.13 %\n",
            "---------------------\n",
            "Training Size: 75 %\n",
            "---------------------\n",
            "Tree # 1 Accuracy: 77.91 %\n",
            "Tree # 2 Accuracy: 77.49 %\n",
            "Tree # 3 Accuracy: 77.33 %\n",
            "Tree # 4 Accuracy: 76.92 %\n",
            "Tree # 5 Accuracy: 76.97 %\n",
            "---------------------\n",
            "Avrage Tree Accuracy for Training Size 75 % : 77.32 %\n",
            "---------------------\n",
            "Training Size: 100 %\n",
            "Tree # 1 Accuracy: 78.05 %\n",
            "Tree # 2 Accuracy: 78.05 %\n",
            "Tree # 3 Accuracy: 78.05 %\n",
            "Tree # 4 Accuracy: 78.05 %\n",
            "Tree # 5 Accuracy: 78.05 %\n",
            "---------------------\n",
            "Avrage Tree Accuracy for Training Size 75 % : 78.05 %\n",
            "---------------------\n"
          ]
        }
      ],
      "source": [
        "train_sizes = [0.25, 0.35, 0.45, 0.55, 0.65, 0.75]\n",
        "ave_acc_list = []\n",
        "\n",
        "print('---------------------')\n",
        "for train_size in train_sizes:\n",
        "  acc_list = []\n",
        "  print('Training Size:', str(int(train_size*100)), '%')\n",
        "  print('---------------------')\n",
        "  for count in range(5):\n",
        "    training_data, _ = train_test_split(data_train, train_size)\n",
        "    _, testing_data = train_test_split(data_test, train_size=0.0)\n",
        "    tree = ID3(training_data,training_data,training_data.columns[:-1])\n",
        "    acc = test(testing_data, tree)\n",
        "    acc_list.append(acc)\n",
        "    print('Tree #', str(count + 1), 'Accuracy:', str(round(acc, 2)),'%')\n",
        "  print('---------------------')\n",
        "  ave_acc_list.append(round(sum(acc_list) / len(acc_list), 2))\n",
        "  print('Avrage Tree Accuracy for Training Size', str(int(train_size*100)), '% :', str(round(sum(acc_list) / len(acc_list), 2)), '%')\n",
        "  print('---------------------')\n",
        "\n",
        "# Train 100%\n",
        "print('Training Size:', '100', '%')\n",
        "acc_list = []\n",
        "for count in range(5):\n",
        "  training_data, _ = train_test_split(data_train, train_size=1.0)\n",
        "  _, testing_data = train_test_split(data_test, train_size=0.0)\n",
        "  tree = ID3(training_data,training_data,training_data.columns[:-1])\n",
        "  acc = test(testing_data, tree)\n",
        "  acc_list.append(acc)\n",
        "  print('Tree #', str(count + 1), 'Accuracy:', str(round(acc, 2)),'%')\n",
        "print('---------------------')\n",
        "ave_acc_list.append(round(sum(acc_list) / len(acc_list), 2))\n",
        "print('Avrage Tree Accuracy for Training Size', str(int(train_size*100)), '% :', str(round(sum(acc_list) / len(acc_list), 2)), '%')\n",
        "print('---------------------')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "HW1-2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
